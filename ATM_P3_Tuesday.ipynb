{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ATM_P3_Tuesday.ipynb",
      "provenance": [],
      "mount_file_id": "19NiQ0GnXSMA6E-Lfa8dq78W_yyh4TELb",
      "authorship_tag": "ABX9TyObfLIZ03H+RkhMWhzG2zjd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurencefrank/Applied-Text-Mining/blob/main/ATM_P3_Tuesday.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La3sgBBjxsIL"
      },
      "source": [
        "## Applied Text Mining, Utrecht Summerschool 26 - 29 July 2021\n",
        "\n",
        "Tuesday 27 July, practical 3\n",
        "\n",
        "### Practical 3: Feature Selection & Dimension Reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_BbI5oCwkD0"
      },
      "source": [
        "from sklearn.datasets import load_files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SEED = 321"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNMvnFDi4sM7"
      },
      "source": [
        "Let's get started!\n",
        "1. Here we are going to use a news article data set, originating from BBC News (http://mlg.ucd.ie/datasets/bbc.html). This data set provided for use as benchmarks for machine learning research. The BBC data set consists of 2225 documents and 5 categories: business, entertainment, politics, sport, and tech. Your first task is to load the dataset so that you can proceed. Do not forget to import the necessary dependencies, you are going to need. You can import the other ones as you go along."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "-8bI-YE04rvz",
        "outputId": "85da2888-6f67-45d4-a34c-8397729cdc47"
      },
      "source": [
        "#/content/drive/MyDrive/Colab Notebooks/AppliedTextMiningSummerschoolUtrechtJuly2021/bbc\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks/AppliedTextMiningSummerschoolUtrechtJuly2021/bbc\"\n",
        "data = load_files(DATA_DIR, encoding=\"utf-8\", decode_error=\"replace\", random_state=SEED)\n",
        "df = pd.DataFrame(list(zip(data['data'], data['target'])), columns=['text', 'label'])\n",
        "df.head()\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chris Evans back on the market\\n\\nBroadcaster ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Giggs handed Wales leading role\\n\\nRyan Giggs ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wales silent on Grand Slam talk\\n\\nRhys Willia...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kenya lift Chepkemei's suspension\\n\\nKenya's a...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lee to create new film superhero\\n\\nComic book...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  Chris Evans back on the market\\n\\nBroadcaster ...      1\n",
              "1  Giggs handed Wales leading role\\n\\nRyan Giggs ...      3\n",
              "2  Wales silent on Grand Slam talk\\n\\nRhys Willia...      3\n",
              "3  Kenya lift Chepkemei's suspension\\n\\nKenya's a...      3\n",
              "4  Lee to create new film superhero\\n\\nComic book...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "4NFR_cBxH2QU",
        "outputId": "55facb45-69bc-438e-be21-35db46e6acc5"
      },
      "source": [
        "df['label'].value_counts().sort_values().plot(kind = 'bar')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f48a20582d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srs71QRFJkbB"
      },
      "source": [
        "2. Print the unique target names in your data and check the number of articles in each category. Then split your data into training (80%) and test (20%) sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQSqZktxIgBv"
      },
      "source": [
        "labels, counts = np.unique(df['label'], return_counts=True) # np.unique(data.target, return_counts=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SyotKggIm0-",
        "outputId": "2797eb36-46af-4aa2-deb0-63c10b317319"
      },
      "source": [
        "data.target_names"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['business', 'entertainment', 'politics', 'sport', 'tech']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5sA-YyXIrlz",
        "outputId": "37a6bb1e-549c-4ab7-add2-dcf60f1926e3"
      },
      "source": [
        "print(dict(zip(data.target_names, counts)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'business': 510, 'entertainment': 386, 'politics': 417, 'sport': 511, 'tech': 401}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kfl9x-PJnkr"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=SEED)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUS3c7FsJyEF"
      },
      "source": [
        "3. Use the CountVectorizer from sklearn and convert the text data into a document-term matrix. What is the difference between CountVectorizer and tfidfVectorizer(use_idf=False)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VBArQ4UMC_X",
        "outputId": "4c7700c4-3bdb-43b3-ab0a-f1ca4ad7dbc9"
      },
      "source": [
        "#nltk.download('RegexpTokenizer')\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading RegexpTokenizer: Package 'RegexpTokenizer'\n",
            "[nltk_data]     not found in index\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8u2mmA5JzYw",
        "outputId": "bd6ec721-bc89-48b8-ddff-0c5a2c8b0f7c"
      },
      "source": [
        "#tokenizer to remove unwanted elements from out data like symbols\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "\n",
        "# Initialize the \"CountVectorizer\" object, which is scikit-learn's bag of words tool.\n",
        "# If you have memory issues, reduce the max_features value so you can continue with the practical\n",
        "vectorizer = CountVectorizer(lowercase=True,\n",
        "                             tokenizer=None,\n",
        "                             stop_words='english',\n",
        "                             ngram_range=(1, 2),\n",
        "                             analyzer='word',\n",
        "                             min_df=3,\n",
        "                             max_features=None)\n",
        "\n",
        "# fit_transform() does two functions: First, it fits the model and learns the vocabulary; \n",
        "# second, it transforms our data into feature vectors. \n",
        "# The input to fit_transform should be a list of strings.\n",
        "bbc_dtm = vectorizer.fit_transform(X_train)\n",
        "print(bbc_dtm.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1780, 23908)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rEHOoXaS23H",
        "outputId": "e17546da-ec6b-4622-cefc-b3568525a71b"
      },
      "source": [
        "type(bbc_dtm)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz3LLPsqOb7r"
      },
      "source": [
        "#In question 3, you don't have to use the RegexpTokenizer as we did not use that. But if you like to use that you can change the code to:\n",
        "#vectorizer = CountVectorizer(lowercase=True,\n",
        "#                             tokenizer=token.tokenize,\n",
        "#                             stop_words='english',\n",
        "#                             ngram_range=(1, 2),\n",
        "#                             analyzer='word',\n",
        "#                             min_df=3,\n",
        "#                            max_features=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRJT-td5KSVA"
      },
      "source": [
        "The only difference is that the TfidfVectorizer() returns floats while the CountVectorizer() returns ints. And that’s to be expected – as explained in the documentation quoted above, TfidfVectorizer() assigns a score while CountVectorizer() counts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G9C7b_uKVul"
      },
      "source": [
        "4. Print top 20 frequent words in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VUXhRoWKUlO",
        "outputId": "f7ef1dc2-8e04-4c11-a860-102f2241be62"
      },
      "source": [
        "importance = np.argsort(np.asarray(bbc_dtm.sum(axis=0)).ravel())[::-1]\n",
        "feature_names = np.array(vectorizer.get_feature_names())\n",
        "feature_names[importance[:20]]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['said', 'mr', 'year', 'people', 'new', 'time', 'world',\n",
              "       'government', 'uk', 'years', 'best', 'just', 'told', 'film',\n",
              "       'make', 'game', 'like', 'music', 'labour', '000'], dtype='<U27')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx3v7hVDRioD"
      },
      "source": [
        "You can also sort the counts based on a document:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "TeCqJNJ_Q86K",
        "outputId": "c2ae8563-44b2-4cba-dc5c-d86188abdce2"
      },
      "source": [
        "counts = pd.DataFrame(bbc_dtm.toarray(),\n",
        "                      columns=vectorizer.get_feature_names())\n",
        "\n",
        "# Show us the top 10 most common words in document 2\n",
        "counts.T.sort_values(by=2, ascending=False).head(10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>1740</th>\n",
              "      <th>1741</th>\n",
              "      <th>1742</th>\n",
              "      <th>1743</th>\n",
              "      <th>1744</th>\n",
              "      <th>1745</th>\n",
              "      <th>1746</th>\n",
              "      <th>1747</th>\n",
              "      <th>1748</th>\n",
              "      <th>1749</th>\n",
              "      <th>1750</th>\n",
              "      <th>1751</th>\n",
              "      <th>1752</th>\n",
              "      <th>1753</th>\n",
              "      <th>1754</th>\n",
              "      <th>1755</th>\n",
              "      <th>1756</th>\n",
              "      <th>1757</th>\n",
              "      <th>1758</th>\n",
              "      <th>1759</th>\n",
              "      <th>1760</th>\n",
              "      <th>1761</th>\n",
              "      <th>1762</th>\n",
              "      <th>1763</th>\n",
              "      <th>1764</th>\n",
              "      <th>1765</th>\n",
              "      <th>1766</th>\n",
              "      <th>1767</th>\n",
              "      <th>1768</th>\n",
              "      <th>1769</th>\n",
              "      <th>1770</th>\n",
              "      <th>1771</th>\n",
              "      <th>1772</th>\n",
              "      <th>1773</th>\n",
              "      <th>1774</th>\n",
              "      <th>1775</th>\n",
              "      <th>1776</th>\n",
              "      <th>1777</th>\n",
              "      <th>1778</th>\n",
              "      <th>1779</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>retailers</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>figures</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sales</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retail</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>december</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>christmas</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ons</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>said</th>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bank england</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 1780 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0     1     2     3     4     ...  1775  1776  1777  1778  1779\n",
              "retailers        0     0     7     0     0  ...     0     0     0     0     0\n",
              "figures          0     0     7     0     0  ...     0     0     0     0     0\n",
              "sales            0     0     6     0     0  ...     0     0     0     0     0\n",
              "retail           0     0     6     0     0  ...     0     0     0     0     0\n",
              "december         0     0     5     0     0  ...     0     0     1     0     0\n",
              "christmas        0     0     5     0     0  ...     0     0     0     0     0\n",
              "ons              0     0     4     0     0  ...     0     0     0     0     0\n",
              "worst            0     0     4     0     0  ...     0     0     0     0     0\n",
              "said             6     3     4     2     0  ...     3     2     4     1     1\n",
              "bank england     0     0     3     0     0  ...     0     0     0     0     0\n",
              "\n",
              "[10 rows x 1780 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y__CwNwMRtCl"
      },
      "source": [
        "## Filter-based feature selection\n",
        "\n",
        "5. From the feature selection library in sklearn load the SelectKBest function and apply it on the BBC dataset using the chi-squared method. Extract top 20 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uARYBCfqR0Ga"
      },
      "source": [
        "X_test_vectorized = vectorizer.transform(X_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7t17zkOTCgp",
        "outputId": "97ab4e0c-598f-4522-d925-33d7b349d975"
      },
      "source": [
        "ch2 = SelectKBest(chi2, k=20)\n",
        "ch2.fit_transform(bbc_dtm, y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1780x20 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 4428 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhwjJSVCTvIF"
      },
      "source": [
        "feature_names_chi = [feature_names[i] for i\n",
        "                         in ch2.get_support(indices=True)]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUTV0dT7T5Cn",
        "outputId": "db108b38-5011-4c63-d9a6-6494b80be6d4"
      },
      "source": [
        "feature_names_chi"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['best',\n",
              " 'blair',\n",
              " 'brown',\n",
              " 'computer',\n",
              " 'digital',\n",
              " 'election',\n",
              " 'film',\n",
              " 'government',\n",
              " 'labour',\n",
              " 'minister',\n",
              " 'mobile',\n",
              " 'mr',\n",
              " 'mr blair',\n",
              " 'music',\n",
              " 'net',\n",
              " 'party',\n",
              " 'people',\n",
              " 'software',\n",
              " 'technology',\n",
              " 'users']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSsMVQIDUB39"
      },
      "source": [
        "6. Extract the 20 top features according to the mutual information feature selection method. Do you get the same list of words as compared to the chi-squared method?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFp-XZ_AT8Df",
        "outputId": "b63bebca-a7f8-4196-e13a-faf7f974264a"
      },
      "source": [
        "mutual_info = SelectKBest(mutual_info_classif, k=20)\n",
        "mutual_info.fit_transform(bbc_dtm, y_train)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1780x20 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 6350 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK409o2UUqTR",
        "outputId": "c9ed11b4-685b-4b86-e345-4281732934b0"
      },
      "source": [
        "feature_names_mutual_info = [feature_names[i] for i\n",
        "                         in mutual_info.get_support(indices=True)]\n",
        "feature_names_mutual_info"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['blair',\n",
              " 'coach',\n",
              " 'election',\n",
              " 'film',\n",
              " 'firm',\n",
              " 'game',\n",
              " 'government',\n",
              " 'labour',\n",
              " 'market',\n",
              " 'minister',\n",
              " 'mr',\n",
              " 'music',\n",
              " 'party',\n",
              " 'people',\n",
              " 'said',\n",
              " 'secretary',\n",
              " 'technology',\n",
              " 'tory',\n",
              " 'users',\n",
              " 'win']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3T9vcSDUwp0"
      },
      "source": [
        "Now you can build a classifier and train it using the output of these feature selection techniques. We are not going to do this right now, but if you are interested you can transform your training and test set using the selected features and continue with your classifier! Here are some tips:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB6HoubRUx6h"
      },
      "source": [
        "# X_train = mutual_info.fit_transform(bbc_dtm, y_train)\n",
        "# X_test = mutual_info.transform(X_test_vectorized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj5Az8E6VAii"
      },
      "source": [
        "## Embedded feature selection\n",
        "\n",
        "7. One of the functions for embedded feature selection is the SelectFromModel function in sklearn. Use this function with L1 norm SVM and check how many non-zero coefficients left in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzEdNKS1VGUy",
        "outputId": "dfaf61d6-4aa5-4798-a197-ba909eda3042"
      },
      "source": [
        "print(\"shape of the matrix before applying the embedded feature selection:\", bbc_dtm.shape)\n",
        "\n",
        "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False)\n",
        "model = SelectFromModel(lsvc).fit(bbc_dtm, y_train) # you can add threshold=0.18 as another argument to select features that have an importance of more than 0.18\n",
        "X_new = model.transform(bbc_dtm)\n",
        "print(\"shape of the matrix after applying the embedded feature selection:\", X_new.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of the matrix before applying the embedded feature selection: (1780, 23908)\n",
            "shape of the matrix after applying the embedded feature selection: (1780, 156)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LnyCf4EVbpk",
        "outputId": "bd5327e4-a6b2-4234-859c-f98a235a42ea"
      },
      "source": [
        "model"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectFromModel(estimator=LinearSVC(C=0.01, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    loss='squared_hinge', max_iter=1000,\n",
              "                                    multi_class='ovr', penalty='l1',\n",
              "                                    random_state=None, tol=0.0001, verbose=0),\n",
              "                max_features=None, norm_order=1, prefit=False, threshold=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-F1ykxnVe23",
        "outputId": "2323f57d-21c6-4e4a-bf91-c30ed24b711f"
      },
      "source": [
        "# you can also check the coefficient values\n",
        "model.estimator_.coef_"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        , -0.08075894,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4h6BY_qVq1w"
      },
      "source": [
        "8. What are the top features according to the SVM model? Tip: Use the function model.get_support() to find these features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4OvoS01Vomg",
        "outputId": "f4b4c472-67e1-474f-9067-dc204ec32de7"
      },
      "source": [
        "model.get_support()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False,  True, False, ..., False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwujY3odVuOP",
        "outputId": "13a802a1-5683-4737-8c35-2612a7bf2ff6"
      },
      "source": [
        "print(\"Features selected by SelectFromModel: \", feature_names[model.get_support()])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features selected by SelectFromModel:  ['000' '2004' 'airlines' 'album' 'analysts' 'apple' 'arsenal' 'athens'\n",
            " 'athletics' 'award' 'ballet' 'ban' 'band' 'bank' 'bbc' 'best' 'bid'\n",
            " 'blair' 'blog' 'book' 'britain' 'british' 'broadband' 'brown' 'business'\n",
            " 'champion' 'chart' 'chelsea' 'chief' 'children' 'china' 'club' 'coach'\n",
            " 'comedy' 'committee' 'companies' 'company' 'computer' 'content' 'council'\n",
            " 'countries' 'cup' 'data' 'deal' 'deutsche' 'digital' 'dollar' 'doping'\n",
            " 'drugs' 'economic' 'economy' 'education' 'election' 'england' 'european'\n",
            " 'euros' 'film' 'final' 'financial' 'firm' 'firms' 'fraud' 'game' 'games'\n",
            " 'gaming' 'glazer' 'good' 'government' 'great' 'group' 'growth' 'half'\n",
            " 'high' 'home' 'howard' 'hunting' 'iaaf' 'including' 'information'\n",
            " 'injury' 'internet' 'ireland' 'jones' 'just' 'labour' 'like' 'liverpool'\n",
            " 'lord' 'mail' 'make' 'market' 'match' 'microsoft' 'million' 'minister'\n",
            " 'mobile' 'mps' 'mr' 'music' 'musical' 'net' 'new' 'nintendo' 'number'\n",
            " 'oil' 'old' 'olympic' 'online' 'party' 'people' 'plans' 'play' 'players'\n",
            " 'police' 'president' 'prices' 'public' 'rights' 'roddick' 'rugby' 'said'\n",
            " 'sales' 'says' 'season' 'secretary' 'series' 'service' 'services' 'set'\n",
            " 'shares' 'singer' 'site' 'software' 'sony' 'spam' 'star' 'stars' 'state'\n",
            " 'team' 'technology' 'time' 'trade' 'tv' 'uk' 'united' 'use' 'users'\n",
            " 'using' 'video' 'virus' 'web' 'win' 'won' 'world' 'year' 'year old']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIvTLIIYV1Zn"
      },
      "source": [
        "## Model comparison\n",
        "\n",
        "9. Create a pipeline with the tfidf representation and a random forest classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAOtJhbTV5-H"
      },
      "source": [
        "clf1 = Pipeline([\n",
        "    ('vectorizer', CountVectorizer()),\n",
        "    ('feature_extraction', TfidfTransformer()),\n",
        "    ('classification', RandomForestClassifier())\n",
        "])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyjfyjGmWAxv"
      },
      "source": [
        "10. Fit the pipeline on the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rV6ieDuWByl",
        "outputId": "e32acd1c-13b6-4d9e-abbf-0c228194b38e"
      },
      "source": [
        "clf1.fit(X_train, y_train)\n",
        "clf1.get_params()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classification': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                        criterion='gini', max_depth=None, max_features='auto',\n",
              "                        max_leaf_nodes=None, max_samples=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=1, min_samples_split=2,\n",
              "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                        n_jobs=None, oob_score=False, random_state=None,\n",
              "                        verbose=0, warm_start=False),\n",
              " 'classification__bootstrap': True,\n",
              " 'classification__ccp_alpha': 0.0,\n",
              " 'classification__class_weight': None,\n",
              " 'classification__criterion': 'gini',\n",
              " 'classification__max_depth': None,\n",
              " 'classification__max_features': 'auto',\n",
              " 'classification__max_leaf_nodes': None,\n",
              " 'classification__max_samples': None,\n",
              " 'classification__min_impurity_decrease': 0.0,\n",
              " 'classification__min_impurity_split': None,\n",
              " 'classification__min_samples_leaf': 1,\n",
              " 'classification__min_samples_split': 2,\n",
              " 'classification__min_weight_fraction_leaf': 0.0,\n",
              " 'classification__n_estimators': 100,\n",
              " 'classification__n_jobs': None,\n",
              " 'classification__oob_score': False,\n",
              " 'classification__random_state': None,\n",
              " 'classification__verbose': 0,\n",
              " 'classification__warm_start': False,\n",
              " 'feature_extraction': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
              " 'feature_extraction__norm': 'l2',\n",
              " 'feature_extraction__smooth_idf': True,\n",
              " 'feature_extraction__sublinear_tf': False,\n",
              " 'feature_extraction__use_idf': True,\n",
              " 'memory': None,\n",
              " 'steps': [('vectorizer',\n",
              "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                   tokenizer=None, vocabulary=None)),\n",
              "  ('feature_extraction',\n",
              "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
              "  ('classification',\n",
              "   RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                          criterion='gini', max_depth=None, max_features='auto',\n",
              "                          max_leaf_nodes=None, max_samples=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                          n_jobs=None, oob_score=False, random_state=None,\n",
              "                          verbose=0, warm_start=False))],\n",
              " 'vectorizer': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                 tokenizer=None, vocabulary=None),\n",
              " 'vectorizer__analyzer': 'word',\n",
              " 'vectorizer__binary': False,\n",
              " 'vectorizer__decode_error': 'strict',\n",
              " 'vectorizer__dtype': numpy.int64,\n",
              " 'vectorizer__encoding': 'utf-8',\n",
              " 'vectorizer__input': 'content',\n",
              " 'vectorizer__lowercase': True,\n",
              " 'vectorizer__max_df': 1.0,\n",
              " 'vectorizer__max_features': None,\n",
              " 'vectorizer__min_df': 1,\n",
              " 'vectorizer__ngram_range': (1, 1),\n",
              " 'vectorizer__preprocessor': None,\n",
              " 'vectorizer__stop_words': None,\n",
              " 'vectorizer__strip_accents': None,\n",
              " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              " 'vectorizer__tokenizer': None,\n",
              " 'vectorizer__vocabulary': None,\n",
              " 'verbose': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztZrGmOCWNdX"
      },
      "source": [
        "11. Use the pipeline to predict the outcome variable on your test set. Evaluate the performance of the pipeline using the classification_report function on the test subset. How do you analyze your results?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zqej7JdWKCg",
        "outputId": "f7838cb2-06d1-4ab5-dbf5-46f954841afd"
      },
      "source": [
        "y_pred1 = clf1.predict(X_test)\n",
        "print(metrics.classification_report(y_test, y_pred1, target_names=data.target_names))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.91      0.97      0.94        92\n",
            "entertainment       1.00      0.90      0.95        84\n",
            "     politics       0.95      0.94      0.94        77\n",
            "        sport       0.96      0.99      0.97       111\n",
            "         tech       0.97      0.96      0.97        81\n",
            "\n",
            "     accuracy                           0.96       445\n",
            "    macro avg       0.96      0.95      0.95       445\n",
            " weighted avg       0.96      0.96      0.96       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT42qbePW5MR"
      },
      "source": [
        "12. Create your second pipeline with the tfidf representation and a random forest classifier with the addition of an embedded feature selection using the SVM classification method with L1 penalty. Fit the pipeline on your training set and test it with the test set. How does the performance change?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyMF5TJCXJYI"
      },
      "source": [
        "clf2 = Pipeline([\n",
        "    ('vectorizer', CountVectorizer()),\n",
        "    ('feature_extraction', TfidfTransformer()),\n",
        "    ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))),\n",
        "    ('classification', RandomForestClassifier())\n",
        "])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vniTjJQ5XL0X",
        "outputId": "9d75355c-416e-440b-88b1-bf9a1f192190"
      },
      "source": [
        "clf2.fit(X_train, y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabula...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=None, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huG9ncGNXRN1",
        "outputId": "767b0e28-d7f0-4cc2-f055-a78a440d5b24"
      },
      "source": [
        "clf2.get_params()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classification': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                        criterion='gini', max_depth=None, max_features='auto',\n",
              "                        max_leaf_nodes=None, max_samples=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=1, min_samples_split=2,\n",
              "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                        n_jobs=None, oob_score=False, random_state=None,\n",
              "                        verbose=0, warm_start=False),\n",
              " 'classification__bootstrap': True,\n",
              " 'classification__ccp_alpha': 0.0,\n",
              " 'classification__class_weight': None,\n",
              " 'classification__criterion': 'gini',\n",
              " 'classification__max_depth': None,\n",
              " 'classification__max_features': 'auto',\n",
              " 'classification__max_leaf_nodes': None,\n",
              " 'classification__max_samples': None,\n",
              " 'classification__min_impurity_decrease': 0.0,\n",
              " 'classification__min_impurity_split': None,\n",
              " 'classification__min_samples_leaf': 1,\n",
              " 'classification__min_samples_split': 2,\n",
              " 'classification__min_weight_fraction_leaf': 0.0,\n",
              " 'classification__n_estimators': 100,\n",
              " 'classification__n_jobs': None,\n",
              " 'classification__oob_score': False,\n",
              " 'classification__random_state': None,\n",
              " 'classification__verbose': 0,\n",
              " 'classification__warm_start': False,\n",
              " 'feature_extraction': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
              " 'feature_extraction__norm': 'l2',\n",
              " 'feature_extraction__smooth_idf': True,\n",
              " 'feature_extraction__sublinear_tf': False,\n",
              " 'feature_extraction__use_idf': True,\n",
              " 'feature_selection': SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False,\n",
              "                                     fit_intercept=True, intercept_scaling=1,\n",
              "                                     loss='squared_hinge', max_iter=1000,\n",
              "                                     multi_class='ovr', penalty='l1',\n",
              "                                     random_state=None, tol=0.0001, verbose=0),\n",
              "                 max_features=None, norm_order=1, prefit=False, threshold=None),\n",
              " 'feature_selection__estimator': LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "           intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "           multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
              "           verbose=0),\n",
              " 'feature_selection__estimator__C': 1.0,\n",
              " 'feature_selection__estimator__class_weight': None,\n",
              " 'feature_selection__estimator__dual': False,\n",
              " 'feature_selection__estimator__fit_intercept': True,\n",
              " 'feature_selection__estimator__intercept_scaling': 1,\n",
              " 'feature_selection__estimator__loss': 'squared_hinge',\n",
              " 'feature_selection__estimator__max_iter': 1000,\n",
              " 'feature_selection__estimator__multi_class': 'ovr',\n",
              " 'feature_selection__estimator__penalty': 'l1',\n",
              " 'feature_selection__estimator__random_state': None,\n",
              " 'feature_selection__estimator__tol': 0.0001,\n",
              " 'feature_selection__estimator__verbose': 0,\n",
              " 'feature_selection__max_features': None,\n",
              " 'feature_selection__norm_order': 1,\n",
              " 'feature_selection__prefit': False,\n",
              " 'feature_selection__threshold': None,\n",
              " 'memory': None,\n",
              " 'steps': [('vectorizer',\n",
              "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                   tokenizer=None, vocabulary=None)),\n",
              "  ('feature_extraction',\n",
              "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
              "  ('feature_selection',\n",
              "   SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False,\n",
              "                                       fit_intercept=True, intercept_scaling=1,\n",
              "                                       loss='squared_hinge', max_iter=1000,\n",
              "                                       multi_class='ovr', penalty='l1',\n",
              "                                       random_state=None, tol=0.0001, verbose=0),\n",
              "                   max_features=None, norm_order=1, prefit=False, threshold=None)),\n",
              "  ('classification',\n",
              "   RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                          criterion='gini', max_depth=None, max_features='auto',\n",
              "                          max_leaf_nodes=None, max_samples=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                          n_jobs=None, oob_score=False, random_state=None,\n",
              "                          verbose=0, warm_start=False))],\n",
              " 'vectorizer': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                 tokenizer=None, vocabulary=None),\n",
              " 'vectorizer__analyzer': 'word',\n",
              " 'vectorizer__binary': False,\n",
              " 'vectorizer__decode_error': 'strict',\n",
              " 'vectorizer__dtype': numpy.int64,\n",
              " 'vectorizer__encoding': 'utf-8',\n",
              " 'vectorizer__input': 'content',\n",
              " 'vectorizer__lowercase': True,\n",
              " 'vectorizer__max_df': 1.0,\n",
              " 'vectorizer__max_features': None,\n",
              " 'vectorizer__min_df': 1,\n",
              " 'vectorizer__ngram_range': (1, 1),\n",
              " 'vectorizer__preprocessor': None,\n",
              " 'vectorizer__stop_words': None,\n",
              " 'vectorizer__strip_accents': None,\n",
              " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              " 'vectorizer__tokenizer': None,\n",
              " 'vectorizer__vocabulary': None,\n",
              " 'verbose': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMlKA800XTey"
      },
      "source": [
        "y_pred2 = clf2.predict(X_test)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHCW3E74Xc4n",
        "outputId": "064a183e-6ef1-41cd-da7b-3f944b418095"
      },
      "source": [
        "print(metrics.classification_report(y_test, y_pred2, target_names=data.target_names))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.91      0.93      0.92        92\n",
            "entertainment       0.97      0.90      0.94        84\n",
            "     politics       0.88      0.90      0.89        77\n",
            "        sport       0.97      0.98      0.98       111\n",
            "         tech       0.95      0.96      0.96        81\n",
            "\n",
            "     accuracy                           0.94       445\n",
            "    macro avg       0.94      0.94      0.94       445\n",
            " weighted avg       0.94      0.94      0.94       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYCmLvyCX1NP"
      },
      "source": [
        "13. Create your third and forth pipelines with the tfidf representation, a chi2 feature selection (with 20 and 200 features for clf3 and clf4, respectively), and a random forest classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSoygqh2X33S"
      },
      "source": [
        "clf3 = Pipeline([\n",
        "    ('vectorizer', CountVectorizer()),\n",
        "    ('feature_extraction', TfidfTransformer()),\n",
        "    ('feature_selection', SelectKBest(chi2, k=20)),\n",
        "    ('classification', RandomForestClassifier())\n",
        "])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck1gnmGKX8r8",
        "outputId": "366c429d-3645-4b0e-fc31-2353862207e4"
      },
      "source": [
        "clf3.fit(X_train, y_train)\n",
        "clf3.get_params()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classification': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                        criterion='gini', max_depth=None, max_features='auto',\n",
              "                        max_leaf_nodes=None, max_samples=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=1, min_samples_split=2,\n",
              "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                        n_jobs=None, oob_score=False, random_state=None,\n",
              "                        verbose=0, warm_start=False),\n",
              " 'classification__bootstrap': True,\n",
              " 'classification__ccp_alpha': 0.0,\n",
              " 'classification__class_weight': None,\n",
              " 'classification__criterion': 'gini',\n",
              " 'classification__max_depth': None,\n",
              " 'classification__max_features': 'auto',\n",
              " 'classification__max_leaf_nodes': None,\n",
              " 'classification__max_samples': None,\n",
              " 'classification__min_impurity_decrease': 0.0,\n",
              " 'classification__min_impurity_split': None,\n",
              " 'classification__min_samples_leaf': 1,\n",
              " 'classification__min_samples_split': 2,\n",
              " 'classification__min_weight_fraction_leaf': 0.0,\n",
              " 'classification__n_estimators': 100,\n",
              " 'classification__n_jobs': None,\n",
              " 'classification__oob_score': False,\n",
              " 'classification__random_state': None,\n",
              " 'classification__verbose': 0,\n",
              " 'classification__warm_start': False,\n",
              " 'feature_extraction': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
              " 'feature_extraction__norm': 'l2',\n",
              " 'feature_extraction__smooth_idf': True,\n",
              " 'feature_extraction__sublinear_tf': False,\n",
              " 'feature_extraction__use_idf': True,\n",
              " 'feature_selection': SelectKBest(k=20, score_func=<function chi2 at 0x7f48a3e07b00>),\n",
              " 'feature_selection__k': 20,\n",
              " 'feature_selection__score_func': <function sklearn.feature_selection._univariate_selection.chi2>,\n",
              " 'memory': None,\n",
              " 'steps': [('vectorizer',\n",
              "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                   tokenizer=None, vocabulary=None)),\n",
              "  ('feature_extraction',\n",
              "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
              "  ('feature_selection',\n",
              "   SelectKBest(k=20, score_func=<function chi2 at 0x7f48a3e07b00>)),\n",
              "  ('classification',\n",
              "   RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                          criterion='gini', max_depth=None, max_features='auto',\n",
              "                          max_leaf_nodes=None, max_samples=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                          n_jobs=None, oob_score=False, random_state=None,\n",
              "                          verbose=0, warm_start=False))],\n",
              " 'vectorizer': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                 tokenizer=None, vocabulary=None),\n",
              " 'vectorizer__analyzer': 'word',\n",
              " 'vectorizer__binary': False,\n",
              " 'vectorizer__decode_error': 'strict',\n",
              " 'vectorizer__dtype': numpy.int64,\n",
              " 'vectorizer__encoding': 'utf-8',\n",
              " 'vectorizer__input': 'content',\n",
              " 'vectorizer__lowercase': True,\n",
              " 'vectorizer__max_df': 1.0,\n",
              " 'vectorizer__max_features': None,\n",
              " 'vectorizer__min_df': 1,\n",
              " 'vectorizer__ngram_range': (1, 1),\n",
              " 'vectorizer__preprocessor': None,\n",
              " 'vectorizer__stop_words': None,\n",
              " 'vectorizer__strip_accents': None,\n",
              " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              " 'vectorizer__tokenizer': None,\n",
              " 'vectorizer__vocabulary': None,\n",
              " 'verbose': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMNxLXneYD9_",
        "outputId": "eb9bdaaa-1f72-4045-aa41-254dc358c225"
      },
      "source": [
        "y_pred3 = clf3.predict(X_test)\n",
        "print(metrics.classification_report(y_test, y_pred3, target_names=data.target_names))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.65      0.46      0.54        92\n",
            "entertainment       0.81      0.56      0.66        84\n",
            "     politics       0.78      0.74      0.76        77\n",
            "        sport       0.63      0.99      0.77       111\n",
            "         tech       0.89      0.81      0.85        81\n",
            "\n",
            "     accuracy                           0.72       445\n",
            "    macro avg       0.75      0.71      0.72       445\n",
            " weighted avg       0.74      0.72      0.71       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYKz8QZvYK9O"
      },
      "source": [
        "clf4 = Pipeline([\n",
        "    ('vectorizer', CountVectorizer()),\n",
        "    ('feature_extraction', TfidfTransformer()),\n",
        "    ('feature_selection', SelectKBest(chi2, k=200)),\n",
        "    ('classification', RandomForestClassifier())\n",
        "])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg8CXAzNYMmb",
        "outputId": "e083c976-3a56-4963-b84c-ff3225cb5abf"
      },
      "source": [
        "clf4.fit(X_train, y_train)\n",
        "clf4.get_params()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classification': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                        criterion='gini', max_depth=None, max_features='auto',\n",
              "                        max_leaf_nodes=None, max_samples=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=1, min_samples_split=2,\n",
              "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                        n_jobs=None, oob_score=False, random_state=None,\n",
              "                        verbose=0, warm_start=False),\n",
              " 'classification__bootstrap': True,\n",
              " 'classification__ccp_alpha': 0.0,\n",
              " 'classification__class_weight': None,\n",
              " 'classification__criterion': 'gini',\n",
              " 'classification__max_depth': None,\n",
              " 'classification__max_features': 'auto',\n",
              " 'classification__max_leaf_nodes': None,\n",
              " 'classification__max_samples': None,\n",
              " 'classification__min_impurity_decrease': 0.0,\n",
              " 'classification__min_impurity_split': None,\n",
              " 'classification__min_samples_leaf': 1,\n",
              " 'classification__min_samples_split': 2,\n",
              " 'classification__min_weight_fraction_leaf': 0.0,\n",
              " 'classification__n_estimators': 100,\n",
              " 'classification__n_jobs': None,\n",
              " 'classification__oob_score': False,\n",
              " 'classification__random_state': None,\n",
              " 'classification__verbose': 0,\n",
              " 'classification__warm_start': False,\n",
              " 'feature_extraction': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
              " 'feature_extraction__norm': 'l2',\n",
              " 'feature_extraction__smooth_idf': True,\n",
              " 'feature_extraction__sublinear_tf': False,\n",
              " 'feature_extraction__use_idf': True,\n",
              " 'feature_selection': SelectKBest(k=200, score_func=<function chi2 at 0x7f48a3e07b00>),\n",
              " 'feature_selection__k': 200,\n",
              " 'feature_selection__score_func': <function sklearn.feature_selection._univariate_selection.chi2>,\n",
              " 'memory': None,\n",
              " 'steps': [('vectorizer',\n",
              "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                   tokenizer=None, vocabulary=None)),\n",
              "  ('feature_extraction',\n",
              "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
              "  ('feature_selection',\n",
              "   SelectKBest(k=200, score_func=<function chi2 at 0x7f48a3e07b00>)),\n",
              "  ('classification',\n",
              "   RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                          criterion='gini', max_depth=None, max_features='auto',\n",
              "                          max_leaf_nodes=None, max_samples=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                          n_jobs=None, oob_score=False, random_state=None,\n",
              "                          verbose=0, warm_start=False))],\n",
              " 'vectorizer': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                 tokenizer=None, vocabulary=None),\n",
              " 'vectorizer__analyzer': 'word',\n",
              " 'vectorizer__binary': False,\n",
              " 'vectorizer__decode_error': 'strict',\n",
              " 'vectorizer__dtype': numpy.int64,\n",
              " 'vectorizer__encoding': 'utf-8',\n",
              " 'vectorizer__input': 'content',\n",
              " 'vectorizer__lowercase': True,\n",
              " 'vectorizer__max_df': 1.0,\n",
              " 'vectorizer__max_features': None,\n",
              " 'vectorizer__min_df': 1,\n",
              " 'vectorizer__ngram_range': (1, 1),\n",
              " 'vectorizer__preprocessor': None,\n",
              " 'vectorizer__stop_words': None,\n",
              " 'vectorizer__strip_accents': None,\n",
              " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              " 'vectorizer__tokenizer': None,\n",
              " 'vectorizer__vocabulary': None,\n",
              " 'verbose': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJh_qDPXYQWE",
        "outputId": "e6863ce6-6733-46cc-8a51-363cb6538bd1"
      },
      "source": [
        "y_pred4 = clf4.predict(X_test)\n",
        "print(metrics.classification_report(y_test, y_pred4, target_names=data.target_names))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.84      0.91      0.87        92\n",
            "entertainment       0.97      0.90      0.94        84\n",
            "     politics       0.93      0.87      0.90        77\n",
            "        sport       0.97      0.98      0.98       111\n",
            "         tech       0.94      0.96      0.95        81\n",
            "\n",
            "     accuracy                           0.93       445\n",
            "    macro avg       0.93      0.93      0.93       445\n",
            " weighted avg       0.93      0.93      0.93       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sChajx70YlL6"
      },
      "source": [
        "14. We can change the learner by simply plugging a different classifier object into our pipeline. Create your fifth pipeline with L1 norm SVM for the feature selection method and naive Bayes for the classifier. Compare your results on the test set with the previous pipelines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thOc3TV-YmRn"
      },
      "source": [
        "clf5 = Pipeline([\n",
        "    ('vectorizer', CountVectorizer()),\n",
        "    ('feature_extraction', TfidfTransformer()),\n",
        "    ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))),\n",
        "    ('classification', MultinomialNB(alpha=0.01))\n",
        "])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpeJP7SVYwAq",
        "outputId": "cf7817e0-561c-43fe-8189-590d18c049ac"
      },
      "source": [
        "clf5.fit(X_train, y_train)\n",
        "clf5.get_params()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classification': MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
              " 'classification__alpha': 0.01,\n",
              " 'classification__class_prior': None,\n",
              " 'classification__fit_prior': True,\n",
              " 'feature_extraction': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
              " 'feature_extraction__norm': 'l2',\n",
              " 'feature_extraction__smooth_idf': True,\n",
              " 'feature_extraction__sublinear_tf': False,\n",
              " 'feature_extraction__use_idf': True,\n",
              " 'feature_selection': SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False,\n",
              "                                     fit_intercept=True, intercept_scaling=1,\n",
              "                                     loss='squared_hinge', max_iter=1000,\n",
              "                                     multi_class='ovr', penalty='l1',\n",
              "                                     random_state=None, tol=0.0001, verbose=0),\n",
              "                 max_features=None, norm_order=1, prefit=False, threshold=None),\n",
              " 'feature_selection__estimator': LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "           intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "           multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
              "           verbose=0),\n",
              " 'feature_selection__estimator__C': 1.0,\n",
              " 'feature_selection__estimator__class_weight': None,\n",
              " 'feature_selection__estimator__dual': False,\n",
              " 'feature_selection__estimator__fit_intercept': True,\n",
              " 'feature_selection__estimator__intercept_scaling': 1,\n",
              " 'feature_selection__estimator__loss': 'squared_hinge',\n",
              " 'feature_selection__estimator__max_iter': 1000,\n",
              " 'feature_selection__estimator__multi_class': 'ovr',\n",
              " 'feature_selection__estimator__penalty': 'l1',\n",
              " 'feature_selection__estimator__random_state': None,\n",
              " 'feature_selection__estimator__tol': 0.0001,\n",
              " 'feature_selection__estimator__verbose': 0,\n",
              " 'feature_selection__max_features': None,\n",
              " 'feature_selection__norm_order': 1,\n",
              " 'feature_selection__prefit': False,\n",
              " 'feature_selection__threshold': None,\n",
              " 'memory': None,\n",
              " 'steps': [('vectorizer',\n",
              "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                   tokenizer=None, vocabulary=None)),\n",
              "  ('feature_extraction',\n",
              "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
              "  ('feature_selection',\n",
              "   SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False,\n",
              "                                       fit_intercept=True, intercept_scaling=1,\n",
              "                                       loss='squared_hinge', max_iter=1000,\n",
              "                                       multi_class='ovr', penalty='l1',\n",
              "                                       random_state=None, tol=0.0001, verbose=0),\n",
              "                   max_features=None, norm_order=1, prefit=False, threshold=None)),\n",
              "  ('classification',\n",
              "   MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True))],\n",
              " 'vectorizer': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                 tokenizer=None, vocabulary=None),\n",
              " 'vectorizer__analyzer': 'word',\n",
              " 'vectorizer__binary': False,\n",
              " 'vectorizer__decode_error': 'strict',\n",
              " 'vectorizer__dtype': numpy.int64,\n",
              " 'vectorizer__encoding': 'utf-8',\n",
              " 'vectorizer__input': 'content',\n",
              " 'vectorizer__lowercase': True,\n",
              " 'vectorizer__max_df': 1.0,\n",
              " 'vectorizer__max_features': None,\n",
              " 'vectorizer__min_df': 1,\n",
              " 'vectorizer__ngram_range': (1, 1),\n",
              " 'vectorizer__preprocessor': None,\n",
              " 'vectorizer__stop_words': None,\n",
              " 'vectorizer__strip_accents': None,\n",
              " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              " 'vectorizer__tokenizer': None,\n",
              " 'vectorizer__vocabulary': None,\n",
              " 'verbose': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL-1UKU_Yygr",
        "outputId": "0bf24a32-2128-416c-f6e3-cfee285956f4"
      },
      "source": [
        "y_pred5 = clf5.predict(X_test)\n",
        "print(metrics.classification_report(y_test, y_pred5, target_names=data.target_names))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.96      0.93      0.95        92\n",
            "entertainment       1.00      0.94      0.97        84\n",
            "     politics       0.95      0.99      0.97        77\n",
            "        sport       1.00      1.00      1.00       111\n",
            "         tech       0.93      0.98      0.95        81\n",
            "\n",
            "     accuracy                           0.97       445\n",
            "    macro avg       0.97      0.97      0.97       445\n",
            " weighted avg       0.97      0.97      0.97       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlfJm16pY7LU"
      },
      "source": [
        "## Dimension reduction\n",
        "\n",
        "15. Dimensionality reduction methods such as PCA and SVD can be used to project the data into a lower dimensional space. If you run PCA with your text data, you might end up with the message \"PCA does not support sparse input. See TruncatedSVD for a possible alternative.\" Therefore, we will use the Truncated SVD function from the sklearn package and we want to find out how much of the variance in the BBC data set is explained with different components. For this, first create a tfidf matrix and use that to make a co-occurrence matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxW5Rs0iY-9o",
        "outputId": "d27ba0a6-aad5-4894-ec2e-fc8a9e5fc7dc"
      },
      "source": [
        "tfidf_vect = TfidfVectorizer()\n",
        "X = tfidf_vect.fit_transform(X_train)\n",
        "Xc = (X.T * X) # this is co-occurrence matrix in sparse csr format\n",
        "Xc.setdiag(0) # sometimes you want to fill same word cooccurence to 0\n",
        "print(\"Shape of the TFIDF vectorizer:\", X.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the TFIDF vectorizer: (1780, 26739)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6yUX8M6ZVpj",
        "outputId": "63da0415-ab60-4509-bd6a-fd2d9d8b425d"
      },
      "source": [
        "print(Xc.todense()) # print out matrix in dense format"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.00024418 0.         ... 0.         0.         0.        ]\n",
            " [0.00024418 0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0u2iOndZYMU",
        "outputId": "a9b8cf5c-d977-438a-8424-14cc1213a9df"
      },
      "source": [
        "tfidf_vect.vocabulary_"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'moya': 16209,\n",
              " 'emotional': 8651,\n",
              " 'at': 2701,\n",
              " 'davis': 6926,\n",
              " 'cup': 6713,\n",
              " 'win': 26258,\n",
              " 'carlos': 4732,\n",
              " 'described': 7350,\n",
              " 'spain': 22477,\n",
              " 'victory': 25605,\n",
              " 'as': 2586,\n",
              " 'the': 24062,\n",
              " 'highlight': 11819,\n",
              " 'of': 17001,\n",
              " 'his': 11872,\n",
              " 'career': 4712,\n",
              " 'after': 1753,\n",
              " 'he': 11591,\n",
              " 'beat': 3292,\n",
              " 'andy': 2196,\n",
              " 'roddick': 20643,\n",
              " 'to': 24311,\n",
              " 'end': 8715,\n",
              " 'usa': 25352,\n",
              " 'challenge': 5012,\n",
              " 'in': 12538,\n",
              " 'seville': 21583,\n",
              " 'made': 14933,\n",
              " 'up': 25285,\n",
              " 'for': 10089,\n",
              " 'missing': 15914,\n",
              " '2000': 428,\n",
              " 'through': 24179,\n",
              " 'injury': 12794,\n",
              " 'by': 4484,\n",
              " 'beating': 3295,\n",
              " 'give': 10798,\n",
              " 'hosts': 12081,\n",
              " 'an': 2147,\n",
              " 'unassailable': 24929,\n",
              " 'lead': 14223,\n",
              " 'have': 11560,\n",
              " 'woken': 26365,\n",
              " 'so': 22302,\n",
              " 'many': 15140,\n",
              " 'nights': 16676,\n",
              " 'dreaming': 8137,\n",
              " 'this': 24124,\n",
              " 'day': 6934,\n",
              " 'said': 20934,\n",
              " 'all': 1955,\n",
              " 'my': 16350,\n",
              " 'energy': 8752,\n",
              " 'has': 11525,\n",
              " 'been': 3342,\n",
              " 'focused': 10027,\n",
              " 'on': 17097,\n",
              " 'today': 24317,\n",
              " 'what': 26113,\n",
              " 'lived': 14610,\n",
              " 'do': 7916,\n",
              " 'not': 16800,\n",
              " 'think': 24111,\n",
              " 'will': 26230,\n",
              " 'live': 14608,\n",
              " 'again': 1760,\n",
              " 'only': 17111,\n",
              " 'other': 17277,\n",
              " 'title': 24300,\n",
              " 'came': 4575,\n",
              " 'two': 24844,\n",
              " 'years': 26599,\n",
              " 'ago': 1797,\n",
              " 'valencia': 25425,\n",
              " 'when': 26127,\n",
              " 'they': 24099,\n",
              " 'australia': 2816,\n",
              " 'and': 2180,\n",
              " 'nicknamed': 16649,\n",
              " 'charly': 5091,\n",
              " 'admitted': 1643,\n",
              " 'is': 13176,\n",
              " 'dream': 8135,\n",
              " 'was': 25919,\n",
              " 'bit': 3648,\n",
              " 'nervous': 16561,\n",
              " 'outset': 17350,\n",
              " 'some': 22373,\n",
              " 'people': 17913,\n",
              " 'that': 24054,\n",
              " 'am': 2046,\n",
              " 'obsessed': 16950,\n",
              " 'but': 4452,\n",
              " 'it': 13220,\n",
              " 'better': 3533,\n",
              " 'way': 25965,\n",
              " 'helps': 11711,\n",
              " 'me': 15467,\n",
              " 'reach': 19543,\n",
              " 'goals': 10896,\n",
              " 'if': 12350,\n",
              " 'really': 19578,\n",
              " 'incredible': 12608,\n",
              " 'get': 10709,\n",
              " 'winning': 26291,\n",
              " 'point': 18391,\n",
              " 'something': 22380,\n",
              " 'spanish': 22488,\n",
              " 'captain': 4680,\n",
              " 'jordi': 13487,\n",
              " 'arrese': 2538,\n",
              " 'played': 18300,\n",
              " 'great': 11085,\n",
              " 'game': 10498,\n",
              " 'opportunity': 17167,\n",
              " 'hasn': 11529,\n",
              " 'let': 14373,\n",
              " 'us': 25351,\n",
              " 'down': 8069,\n",
              " 'had': 11313,\n",
              " 'lost': 14750,\n",
              " 'three': 24158,\n",
              " 'times': 24259,\n",
              " 'him': 11839,\n",
              " 'waiting': 25820,\n",
              " 'be': 3266,\n",
              " 'position': 18525,\n",
              " 'also': 2021,\n",
              " 'remarkable': 20007,\n",
              " 'performance': 17946,\n",
              " 'rafael': 19368,\n",
              " 'nadal': 16373,\n",
              " 'who': 26173,\n",
              " 'opening': 17137,\n",
              " 'singles': 22020,\n",
              " 'aged': 1765,\n",
              " '18': 273,\n",
              " '185': 290,\n",
              " 'days': 6938,\n",
              " 'mallorcan': 15052,\n",
              " 'became': 3314,\n",
              " 'youngest': 26642,\n",
              " 'player': 18301,\n",
              " 'finish': 9808,\n",
              " 'year': 26595,\n",
              " 'afterwards': 1757,\n",
              " 'coach': 5541,\n",
              " 'patrick': 17763,\n",
              " 'mcenroe': 15416,\n",
              " 'wants': 25871,\n",
              " 'rest': 20254,\n",
              " 'team': 23835,\n",
              " 'play': 18294,\n",
              " 'more': 16105,\n",
              " 'tennis': 23954,\n",
              " 'clay': 5410,\n",
              " 'hone': 11992,\n",
              " 'their': 24071,\n",
              " 'skills': 22086,\n",
              " 'surface': 23428,\n",
              " 'help': 11705,\n",
              " 'these': 24098,\n",
              " 'guys': 11285,\n",
              " 'even': 9083,\n",
              " 'slow': 22183,\n",
              " 'hard': 11459,\n",
              " 'courts': 6453,\n",
              " 'learn': 14258,\n",
              " 'how': 12124,\n",
              " 'mix': 15944,\n",
              " 'things': 24110,\n",
              " 'little': 14603,\n",
              " 'smarter': 22214,\n",
              " 'tactically': 23661,\n",
              " 'obviously': 16963,\n",
              " 'unrealistic': 25202,\n",
              " 'say': 21091,\n",
              " 'we': 25974,\n",
              " 're': 19541,\n",
              " 'going': 10915,\n",
              " 'just': 13586,\n",
              " 'start': 22840,\n",
              " 'playing': 18304,\n",
              " 'constantly': 6090,\n",
              " 'with': 26325,\n",
              " 'schedule': 21155,\n",
              " 'certainly': 4972,\n",
              " 'can': 4602,\n",
              " 'put': 19204,\n",
              " 'work': 26420,\n",
              " 'appropriate': 2415,\n",
              " 'time': 24253,\n",
              " 'couple': 6433,\n",
              " 'events': 9088,\n",
              " 'against': 1761,\n",
              " 'are': 2471,\n",
              " 'best': 3513,\n",
              " 'stuff': 23180,\n",
              " 'left': 14290,\n",
              " 'frustrated': 10358,\n",
              " 'losing': 14746,\n",
              " 'both': 3970,\n",
              " 'olympic': 17085,\n",
              " 'stadium': 22755,\n",
              " 'tough': 24434,\n",
              " 'because': 3315,\n",
              " 'felt': 9634,\n",
              " 'like': 14494,\n",
              " 'whole': 26176,\n",
              " 'one': 17101,\n",
              " 'top': 24372,\n",
              " 'courters': 6446,\n",
              " 'world': 26443,\n",
              " 'american': 2093,\n",
              " 'chances': 5034,\n",
              " 'didn': 7525,\n",
              " 'convert': 6237,\n",
              " 'them': 24074,\n",
              " 'bottom': 3980,\n",
              " 'line': 14538,\n",
              " 'were': 26082,\n",
              " 'than': 24045,\n",
              " 'weekend': 26030,\n",
              " 'out': 17291,\n",
              " 'took': 24362,\n",
              " 'care': 4710,\n",
              " 'business': 4443,\n",
              " 'simple': 21979,\n",
              " 'bryan': 4294,\n",
              " 'twins': 24837,\n",
              " 'keep': 13697,\n",
              " 'hopes': 12031,\n",
              " 'alive': 1954,\n",
              " 'united': 25136,\n",
              " 'states': 22857,\n",
              " 'kept': 13737,\n",
              " 'final': 9767,\n",
              " 'saturday': 21060,\n",
              " 'doubles': 8052,\n",
              " 'rubber': 20789,\n",
              " 'leaving': 14271,\n",
              " 'ahead': 1816,\n",
              " 'into': 13020,\n",
              " 'masters': 15295,\n",
              " 'champions': 5026,\n",
              " 'mike': 15763,\n",
              " 'bob': 3819,\n",
              " 'thrashed': 24148,\n",
              " 'juan': 13520,\n",
              " 'ferrero': 9661,\n",
              " 'tommy': 24345,\n",
              " 'robredo': 20617,\n",
              " 'front': 10335,\n",
              " 'partisan': 17694,\n",
              " 'crowd': 6627,\n",
              " 'would': 26467,\n",
              " 'given': 10801,\n",
              " 'outclassed': 17297,\n",
              " 'sunday': 23345,\n",
              " 'reverse': 20377,\n",
              " 'takes': 23690,\n",
              " 'before': 3349,\n",
              " 'faces': 9388,\n",
              " 'mardy': 15169,\n",
              " 'fish': 9863,\n",
              " 'feels': 9613,\n",
              " 'good': 10942,\n",
              " 'don': 7990,\n",
              " 'tomorrow': 24346,\n",
              " 'those': 24139,\n",
              " 'another': 2284,\n",
              " 'shot': 21827,\n",
              " 'go': 10889,\n",
              " 'sleep': 22141,\n",
              " 'added': 1586,\n",
              " 'confident': 5959,\n",
              " 'first': 9854,\n",
              " 'match': 15301,\n",
              " 'then': 24079,\n",
              " 'anything': 2330,\n",
              " 'happen': 11443,\n",
              " 'chose': 5247,\n",
              " 'old': 17063,\n",
              " 'epic': 8890,\n",
              " 'over': 17372,\n",
              " 'friday': 10310,\n",
              " 'replaced': 20115,\n",
              " 'former': 10147,\n",
              " 'number': 16872,\n",
              " 'pair': 17541,\n",
              " 'depth': 7320,\n",
              " 'teams': 23838,\n",
              " '26': 544,\n",
              " 'won': 26382,\n",
              " 'four': 10196,\n",
              " 'matches': 15304,\n",
              " 'quickly': 19286,\n",
              " 'silenced': 21952,\n",
              " 'huge': 12154,\n",
              " 'racing': 19335,\n",
              " 'set': 21552,\n",
              " 'love': 14767,\n",
              " 'spaniards': 22487,\n",
              " 'twice': 24831,\n",
              " 'surrendered': 23457,\n",
              " 'breaks': 4110,\n",
              " 'serve': 21540,\n",
              " 'second': 21363,\n",
              " 'bryans': 4295,\n",
              " 'broke': 4230,\n",
              " 'served': 21541,\n",
              " 'dropped': 8178,\n",
              " 'third': 24117,\n",
              " 'unflappable': 25085,\n",
              " 'brothers': 4256,\n",
              " 'powered': 18590,\n",
              " 'impressive': 12516,\n",
              " 'upset': 25322,\n",
              " 'hinted': 11857,\n",
              " 'further': 10431,\n",
              " 'dissatisfaction': 7813,\n",
              " 'defeat': 7086,\n",
              " 'difficult': 7548,\n",
              " 'players': 18302,\n",
              " 'everything': 9103,\n",
              " 'calculated': 4534,\n",
              " 'very': 25557,\n",
              " 'surprised': 23450,\n",
              " 'named': 16392,\n",
              " 'hardly': 11472,\n",
              " 'badly': 2989,\n",
              " 'right': 20505,\n",
              " 'christmas': 5259,\n",
              " 'sales': 20955,\n",
              " 'worst': 26460,\n",
              " 'since': 22004,\n",
              " '1981': 395,\n",
              " 'uk': 24885,\n",
              " 'retail': 20299,\n",
              " 'fell': 9626,\n",
              " 'december': 7011,\n",
              " 'failing': 9417,\n",
              " 'meet': 15522,\n",
              " 'expectations': 9245,\n",
              " 'making': 15020,\n",
              " 'counts': 6429,\n",
              " 'month': 16078,\n",
              " 'rise': 20551,\n",
              " 'november': 16846,\n",
              " 'office': 17021,\n",
              " 'national': 16450,\n",
              " 'statistics': 22866,\n",
              " 'ons': 17113,\n",
              " 'revised': 20391,\n",
              " 'annual': 2270,\n",
              " '2004': 434,\n",
              " 'rate': 19496,\n",
              " 'growth': 11187,\n",
              " 'from': 10333,\n",
              " 'estimated': 9008,\n",
              " 'retailers': 20301,\n",
              " 'already': 2019,\n",
              " 'reported': 20129,\n",
              " 'poor': 18464,\n",
              " 'figures': 9739,\n",
              " 'clothing': 5508,\n",
              " 'non': 16751,\n",
              " 'specialist': 22528,\n",
              " 'stores': 23031,\n",
              " 'hit': 11883,\n",
              " 'internet': 12982,\n",
              " 'showing': 21851,\n",
              " 'any': 2325,\n",
              " 'significant': 21943,\n",
              " 'according': 1473,\n",
              " 'last': 14144,\n",
              " 'endured': 8741,\n",
              " 'tougher': 24436,\n",
              " '23': 502,\n",
              " 'previously': 18780,\n",
              " 'plunged': 18359,\n",
              " 'echoed': 8379,\n",
              " 'earlier': 8318,\n",
              " 'caution': 4873,\n",
              " 'bank': 3095,\n",
              " 'england': 8778,\n",
              " 'governor': 10998,\n",
              " 'mervyn': 15649,\n",
              " 'king': 13820,\n",
              " 'read': 19553,\n",
              " 'too': 24361,\n",
              " 'much': 16240,\n",
              " 'analysts': 2160,\n",
              " 'positive': 18530,\n",
              " 'gloss': 10864,\n",
              " 'pointing': 18395,\n",
              " 'seasonally': 21345,\n",
              " 'adjusted': 1620,\n",
              " 'showed': 21847,\n",
              " 'comparable': 5784,\n",
              " '2003': 433,\n",
              " 'jump': 13560,\n",
              " 'roughly': 20738,\n",
              " 'recent': 19643,\n",
              " 'averages': 2874,\n",
              " 'although': 2032,\n",
              " 'below': 3423,\n",
              " 'serious': 21530,\n",
              " 'booms': 3916,\n",
              " 'seen': 21408,\n",
              " '1990s': 406,\n",
              " 'volume': 25755,\n",
              " 'outperformed': 17338,\n",
              " 'measures': 15486,\n",
              " 'actual': 1562,\n",
              " 'spending': 22577,\n",
              " 'indication': 12640,\n",
              " 'consumers': 6120,\n",
              " 'looking': 14718,\n",
              " 'bargains': 3139,\n",
              " 'cutting': 6771,\n",
              " 'prices': 18784,\n",
              " 'however': 12131,\n",
              " 'reports': 20134,\n",
              " 'high': 11807,\n",
              " 'street': 23094,\n",
              " 'weakness': 25981,\n",
              " 'sector': 21380,\n",
              " 'morrisons': 16126,\n",
              " 'woolworths': 26412,\n",
              " 'house': 12107,\n",
              " 'fraser': 10249,\n",
              " 'marks': 15209,\n",
              " 'spencer': 22575,\n",
              " 'big': 3578,\n",
              " 'food': 10067,\n",
              " 'festive': 9676,\n",
              " 'period': 17957,\n",
              " 'disappointing': 7647,\n",
              " 'british': 4195,\n",
              " 'consortium': 6081,\n",
              " 'survey': 23468,\n",
              " 'found': 10188,\n",
              " '10': 55,\n",
              " 'yet': 26614,\n",
              " 'including': 12582,\n",
              " 'hmv': 11903,\n",
              " 'monsoon': 16067,\n",
              " 'jessops': 13387,\n",
              " 'body': 3832,\n",
              " 'shop': 21803,\n",
              " 'tesco': 23995,\n",
              " 'well': 26064,\n",
              " 'investec': 13068,\n",
              " 'chief': 5182,\n",
              " 'economist': 8393,\n",
              " 'philip': 18088,\n",
              " 'shaw': 21688,\n",
              " 'did': 7521,\n",
              " 'expect': 9242,\n",
              " 'immediate': 12433,\n",
              " 'effect': 8447,\n",
              " 'interest': 12958,\n",
              " 'rates': 19498,\n",
              " 'weak': 25975,\n",
              " 'indicated': 12637,\n",
              " 'night': 16671,\n",
              " 'you': 26638,\n",
              " 'accurate': 1498,\n",
              " 'impression': 12513,\n",
              " 'trading': 24502,\n",
              " 'until': 25255,\n",
              " 'about': 1381,\n",
              " 'easter': 8349,\n",
              " 'mr': 16225,\n",
              " 'our': 17285,\n",
              " 'view': 25618,\n",
              " 'its': 13233,\n",
              " 'powder': 18585,\n",
              " 'dry': 8200,\n",
              " 'wait': 25816,\n",
              " 'see': 21393,\n",
              " 'picture': 18146,\n",
              " 'jones': 13479,\n",
              " 'medals': 15499,\n",
              " 'must': 16332,\n",
              " 'guilty': 11239,\n",
              " 'anti': 2302,\n",
              " 'doping': 8028,\n",
              " 'agency': 1771,\n",
              " 'wada': 25800,\n",
              " 'dick': 7509,\n",
              " 'pound': 18576,\n",
              " 'says': 21095,\n",
              " 'marion': 15191,\n",
              " 'should': 21829,\n",
              " 'stripped': 23135,\n",
              " 'her': 11735,\n",
              " 'taking': 23691,\n",
              " 'banned': 3108,\n",
              " 'substances': 23243,\n",
              " 'victor': 25599,\n",
              " 'conte': 6136,\n",
              " 'balco': 3030,\n",
              " 'laboratories': 14012,\n",
              " 'claims': 5350,\n",
              " 'sprinter': 22686,\n",
              " 'regularly': 19872,\n",
              " 'used': 25362,\n",
              " 'drugs': 8189,\n",
              " 'enhance': 8782,\n",
              " 'she': 21692,\n",
              " 'asked': 2618,\n",
              " 'there': 24089,\n",
              " 'timescale': 24260,\n",
              " 'could': 6399,\n",
              " 'taken': 23686,\n",
              " 'issue': 13212,\n",
              " 'under': 24987,\n",
              " 'international': 12977,\n",
              " 'committee': 5754,\n",
              " 'ioc': 13106,\n",
              " 'rules': 20826,\n",
              " 'athletes': 2706,\n",
              " 'caught': 4865,\n",
              " 'within': 26336,\n",
              " 'event': 9087,\n",
              " 'five': 9879,\n",
              " 'olympics': 17086,\n",
              " 'denies': 7251,\n",
              " 'using': 25373,\n",
              " 'take': 23684,\n",
              " 'legal': 14295,\n",
              " 'action': 1546,\n",
              " 'allegations': 1965,\n",
              " 'firm': 9849,\n",
              " 'centre': 4952,\n",
              " 'wide': 26189,\n",
              " 'reaching': 19546,\n",
              " 'investigation': 13074,\n",
              " 'continued': 6171,\n",
              " 'indeed': 12619,\n",
              " 'disappointment': 7649,\n",
              " 'lot': 14752,\n",
              " 'eminem': 8639,\n",
              " 'secret': 21369,\n",
              " 'gig': 10750,\n",
              " 'venue': 25525,\n",
              " 'revealed': 20359,\n",
              " 'rapper': 19473,\n",
              " 'intimate': 13013,\n",
              " 'london': 14696,\n",
              " 'following': 10054,\n",
              " 'show': 21839,\n",
              " 'river': 20570,\n",
              " 'thames': 24044,\n",
              " 'star': 22822,\n",
              " 'songs': 22388,\n",
              " 'showcasing': 21845,\n",
              " 'label': 14007,\n",
              " 'shady': 21618,\n",
              " 'records': 19697,\n",
              " 'islington': 13197,\n",
              " 'academy': 1422,\n",
              " 'performed': 17948,\n",
              " 'hms': 11902,\n",
              " 'belfast': 3385,\n",
              " 'which': 26135,\n",
              " 'docked': 7922,\n",
              " 'where': 26129,\n",
              " 'filmed': 9753,\n",
              " 'bbc': 3259,\n",
              " 'pops': 18473,\n",
              " 'arrived': 2547,\n",
              " 'appearance': 2366,\n",
              " 'mtv': 16237,\n",
              " 'europe': 9046,\n",
              " 'music': 16318,\n",
              " 'awards': 2900,\n",
              " 'rome': 20675,\n",
              " 'rap': 19467,\n",
              " 'acts': 1561,\n",
              " 'may': 15365,\n",
              " 'appear': 2365,\n",
              " 'include': 12579,\n",
              " 'stat': 22850,\n",
              " 'quo': 19309,\n",
              " 'proof': 18980,\n",
              " 'dj': 7905,\n",
              " 'green': 11097,\n",
              " 'lantern': 14115,\n",
              " 'swift': 23568,\n",
              " 'obie': 16918,\n",
              " 'trice': 24646,\n",
              " 'latest': 14152,\n",
              " 'album': 1901,\n",
              " 'soared': 22307,\n",
              " 'chart': 5095,\n",
              " 'sale': 20954,\n",
              " 'record': 19690,\n",
              " 'shops': 21808,\n",
              " 'encore': 8701,\n",
              " 'now': 16851,\n",
              " 'topper': 24377,\n",
              " 'sides': 21910,\n",
              " 'atlantic': 2717,\n",
              " 'debut': 6993,\n",
              " 'fourth': 10200,\n",
              " 'outsold': 17356,\n",
              " 'rivals': 20569,\n",
              " 'released': 19958,\n",
              " 'early': 8321,\n",
              " 'effort': 8457,\n",
              " 'combat': 5681,\n",
              " 'physical': 18119,\n",
              " 'online': 17110,\n",
              " 'piracy': 18210,\n",
              " 'includes': 12581,\n",
              " 'track': 24483,\n",
              " 'mosh': 16135,\n",
              " 'tirade': 24286,\n",
              " 'president': 18734,\n",
              " 'bush': 4439,\n",
              " 'presence': 18716,\n",
              " 'troops': 24701,\n",
              " 'iraq': 13130,\n",
              " 'criticised': 6591,\n",
              " 'april': 2426,\n",
              " 'led': 14282,\n",
              " '12': 119,\n",
              " 'viewers': 25621,\n",
              " 'complain': 5825,\n",
              " 'lewd': 14395,\n",
              " 'offensive': 17014,\n",
              " 'complaints': 5830,\n",
              " 'grabbing': 11009,\n",
              " 'crotch': 6623,\n",
              " 'upheld': 25301,\n",
              " 'performer': 17949,\n",
              " 'tone': 24348,\n",
              " 'act': 1543,\n",
              " 'rehearsal': 19885,\n",
              " 'ignored': 12368,\n",
              " 'request': 20160,\n",
              " 'during': 8269,\n",
              " 'broadcast': 4212,\n",
              " 'statement': 22854,\n",
              " 'gestures': 10708,\n",
              " 'part': 17678,\n",
              " 'culture': 6699,\n",
              " 'gone': 10933,\n",
              " 'beyond': 3550,\n",
              " 'expected': 9246,\n",
              " 'loses': 14745,\n",
              " 'customer': 6757,\n",
              " 'details': 7414,\n",
              " 'america': 2092,\n",
              " 'computer': 5878,\n",
              " 'tapes': 23751,\n",
              " 'containing': 6134,\n",
              " 'account': 1476,\n",
              " 'million': 15790,\n",
              " 'customers': 6758,\n",
              " 'federal': 9596,\n",
              " 'employees': 8670,\n",
              " 'several': 21577,\n",
              " 'members': 15569,\n",
              " 'senate': 21457,\n",
              " 'among': 2118,\n",
              " 'affected': 1725,\n",
              " 'vulnerable': 25791,\n",
              " 'identity': 12324,\n",
              " 'theft': 24070,\n",
              " 'sources': 22442,\n",
              " 'stolen': 23009,\n",
              " 'plane': 18261,\n",
              " 'baggage': 2999,\n",
              " 'handlers': 11410,\n",
              " 'gave': 10581,\n",
              " 'no': 16718,\n",
              " 'disappeared': 7643,\n",
              " 'probably': 18851,\n",
              " 'misused': 15933,\n",
              " 'accounts': 1484,\n",
              " 'being': 3375,\n",
              " 'monitoring': 16055,\n",
              " 'holders': 11942,\n",
              " 'notified': 16821,\n",
              " 'unusual': 25263,\n",
              " 'activity': 1556,\n",
              " 'detected': 7421,\n",
              " 'officials': 17027,\n",
              " 'went': 26079,\n",
              " 'while': 26138,\n",
              " 'shipped': 21765,\n",
              " 'back': 2945,\n",
              " 'data': 6905,\n",
              " 'law': 14191,\n",
              " 'authorities': 2837,\n",
              " 'done': 7999,\n",
              " 'robust': 20620,\n",
              " 'thorough': 24134,\n",
              " 'neither': 16547,\n",
              " 'nor': 16761,\n",
              " 'make': 15012,\n",
              " 'lightly': 14489,\n",
              " 'believe': 3395,\n",
              " 'alexandra': 1923,\n",
              " 'tower': 24460,\n",
              " 'spokeswoman': 22635,\n",
              " 'north': 16780,\n",
              " 'carolina': 4747,\n",
              " 'based': 3194,\n",
              " 'told': 24329,\n",
              " 'magazine': 14950,\n",
              " 'evidence': 9110,\n",
              " 'criminal': 6569,\n",
              " 'service': 21545,\n",
              " 'whose': 26185,\n",
              " 'brief': 4159,\n",
              " 'investigations': 13075,\n",
              " 'financial': 9779,\n",
              " 'crime': 6567,\n",
              " 'loss': 14747,\n",
              " 'new': 16598,\n",
              " 'york': 26633,\n",
              " 'senator': 21458,\n",
              " 'charles': 5086,\n",
              " 'schumer': 21200,\n",
              " 'commercial': 5735,\n",
              " 'whether': 26134,\n",
              " 'terrorism': 23990,\n",
              " 'or': 17193,\n",
              " 'complicated': 5845,\n",
              " 'background': 2960,\n",
              " 'checks': 5132,\n",
              " 'hired': 11866,\n",
              " 'increasingly': 12607,\n",
              " 'sensitive': 21480,\n",
              " 'positions': 18529,\n",
              " 'democrat': 7218,\n",
              " 'vermont': 25544,\n",
              " 'colleague': 5632,\n",
              " 'pat': 17737,\n",
              " 'leahy': 14237,\n",
              " 'credit': 6540,\n",
              " 'card': 4701,\n",
              " 'tracy': 24493,\n",
              " 'schmaler': 21171,\n",
              " '900': 1245,\n",
              " '000': 1,\n",
              " 'military': 15781,\n",
              " 'civilian': 5336,\n",
              " 'staff': 22757,\n",
              " 'defence': 7096,\n",
              " 'department': 7273,\n",
              " 'pentagon': 17910,\n",
              " 'spokesman': 22632,\n",
              " 'bollywood': 3860,\n",
              " 'dvd': 8281,\n",
              " 'fraudster': 10256,\n",
              " 'jailed': 13279,\n",
              " 'major': 15005,\n",
              " 'distributor': 7854,\n",
              " 'pirated': 18212,\n",
              " 'dvds': 8282,\n",
              " 'films': 9760,\n",
              " 'sent': 21485,\n",
              " 'prison': 18826,\n",
              " 'jayanti': 13336,\n",
              " 'amarishi': 2054,\n",
              " 'buhecha': 4339,\n",
              " 'cambridge': 4572,\n",
              " 'trademark': 24496,\n",
              " 'offences': 17008,\n",
              " 'sentenced': 21488,\n",
              " 'harrow': 11510,\n",
              " 'crown': 6632,\n",
              " 'court': 6442,\n",
              " 'tuesday': 24763,\n",
              " 'per': 17925,\n",
              " 'illegal': 12381,\n",
              " 'trade': 24494,\n",
              " 'called': 4552,\n",
              " 'biggest': 3580,\n",
              " 'pirates': 18213,\n",
              " 'sentencing': 21491,\n",
              " 'judge': 13528,\n",
              " 'phonographic': 18106,\n",
              " 'industry': 12685,\n",
              " 'bpi': 4037,\n",
              " 'worked': 26422,\n",
              " 'case': 4796,\n",
              " 'operation': 17149,\n",
              " 'launched': 14171,\n",
              " '2002': 432,\n",
              " 'received': 19638,\n",
              " 'activities': 1555,\n",
              " 'lasted': 14145,\n",
              " 'seven': 21571,\n",
              " 'heavy': 11652,\n",
              " 'penalty': 17887,\n",
              " 'enormous': 8805,\n",
              " 'damage': 6834,\n",
              " 'caused': 4868,\n",
              " 'legitimate': 14310,\n",
              " 'fake': 9439,\n",
              " 'manufactured': 15134,\n",
              " 'pakistan': 17549,\n",
              " 'malaysia': 15027,\n",
              " 'sold': 22347,\n",
              " 'wholesale': 26179,\n",
              " 'traded': 24495,\n",
              " 'conterfeit': 6154,\n",
              " 'stopped': 23023,\n",
              " 'car': 4693,\n",
              " 'standards': 22802,\n",
              " 'officers': 17023,\n",
              " 'uncovered': 24976,\n",
              " 'faked': 9440,\n",
              " 'inlay': 12804,\n",
              " 'cards': 4708,\n",
              " 'printed': 18814,\n",
              " 'registered': 19856,\n",
              " 'trademarks': 24497,\n",
              " 'despite': 7392,\n",
              " 'arrested': 2540,\n",
              " 'bailed': 3012,\n",
              " 'home': 11973,\n",
              " 'lock': 14665,\n",
              " 'contain': 6131,\n",
              " 'counterfeit': 6414,\n",
              " 'suspended': 23489,\n",
              " 'sued': 23289,\n",
              " 'employers': 8672,\n",
              " 'dealing': 6964,\n",
              " 'copies': 6284,\n",
              " 'classic': 5390,\n",
              " 'mohabbatein': 16009,\n",
              " 'film': 9752,\n",
              " 'distributors': 7855,\n",
              " 'hailed': 11322,\n",
              " 'conviction': 6247,\n",
              " 'boost': 3921,\n",
              " 'suffers': 23297,\n",
              " '40': 771,\n",
              " 'suffered': 23294,\n",
              " 'mainstream': 14997,\n",
              " 'productions': 18892,\n",
              " 'welcomed': 26060,\n",
              " 'news': 16613,\n",
              " 'sentence': 21487,\n",
              " 'warned': 25899,\n",
              " 'plenty': 18332,\n",
              " 'active': 1551,\n",
              " 'counterfeiters': 6415,\n",
              " 'organisation': 17220,\n",
              " 'director': 7616,\n",
              " 'david': 6923,\n",
              " 'martin': 15244,\n",
              " 'problem': 18858,\n",
              " 'simply': 21988,\n",
              " 'disappear': 7641,\n",
              " 'others': 17278,\n",
              " 'place': 18245,\n",
              " 'vital': 25710,\n",
              " 'efforts': 8459,\n",
              " 'field': 9712,\n",
              " 'german': 10696,\n",
              " 'goes': 10912,\n",
              " 'germany': 10699,\n",
              " 'economy': 8395,\n",
              " 'shrank': 21858,\n",
              " 'months': 16080,\n",
              " 'upsetting': 25324,\n",
              " 'sustained': 23503,\n",
              " 'recovery': 19707,\n",
              " 'confounded': 5978,\n",
              " 'expansion': 9237,\n",
              " 'quarter': 19252,\n",
              " 'contraction': 6184,\n",
              " 'estimate': 9007,\n",
              " 'zero': 26706,\n",
              " 'putting': 19208,\n",
              " 'standstill': 22810,\n",
              " 'july': 13557,\n",
              " 'onward': 17123,\n",
              " 'reliant': 19970,\n",
              " 'exports': 9311,\n",
              " 'unemployment': 25065,\n",
              " 'impending': 12465,\n",
              " 'cuts': 6768,\n",
              " 'welfare': 26063,\n",
              " 'mean': 15472,\n",
              " 'money': 16044,\n",
              " 'themselves': 24078,\n",
              " 'companies': 5780,\n",
              " 'volkswagen': 25752,\n",
              " 'daimlerchrysler': 6818,\n",
              " 'siemens': 21922,\n",
              " 'spent': 22579,\n",
              " 'talks': 23707,\n",
              " 'unions': 25129,\n",
              " 'trimming': 24669,\n",
              " 'jobs': 13431,\n",
              " 'costs': 6383,\n",
              " 'destatis': 7397,\n",
              " 'rising': 20555,\n",
              " 'outweighed': 17369,\n",
              " 'continuing': 6173,\n",
              " 'domestic': 7973,\n",
              " 'demand': 7202,\n",
              " 'relentless': 19964,\n",
              " 'value': 25441,\n",
              " 'euro': 9040,\n",
              " 'competitiveness': 5814,\n",
              " 'products': 18895,\n",
              " 'overseas': 17424,\n",
              " 'depress': 7312,\n",
              " 'prospects': 19018,\n",
              " 'nation': 16449,\n",
              " 'eurozone': 9056,\n",
              " 'senior': 21469,\n",
              " 'setting': 21560,\n",
              " 'european': 9047,\n",
              " 'central': 4946,\n",
              " 'beginning': 3356,\n",
              " 'talk': 23702,\n",
              " 'threat': 24151,\n",
              " 'inflation': 12729,\n",
              " 'prompting': 18972,\n",
              " 'fears': 9582,\n",
              " 'ecb': 8373,\n",
              " 'mandate': 15082,\n",
              " 'fight': 9729,\n",
              " 'boosting': 3923,\n",
              " 'threaten': 24152,\n",
              " 'tautou': 23806,\n",
              " 'da': 6800,\n",
              " 'vinci': 25655,\n",
              " 'french': 10293,\n",
              " 'actress': 1559,\n",
              " 'audrey': 2802,\n",
              " 'amelie': 2083,\n",
              " 'female': 9635,\n",
              " 'adaptation': 1574,\n",
              " 'code': 5577,\n",
              " 'movie': 16203,\n",
              " 'version': 25551,\n",
              " 'dan': 6852,\n",
              " 'brown': 4259,\n",
              " 'selling': 21442,\n",
              " 'novel': 16841,\n",
              " 'directed': 7609,\n",
              " 'ron': 20681,\n",
              " 'howard': 12125,\n",
              " 'stars': 22837,\n",
              " 'tom': 24337,\n",
              " 'hanks': 11427,\n",
              " 'cracking': 6487,\n",
              " 'partner': 17698,\n",
              " 'various': 25471,\n",
              " 'newspapers': 16618,\n",
              " 'currently': 6734,\n",
              " 'starring': 22836,\n",
              " 'long': 14704,\n",
              " 'engagement': 8764,\n",
              " 'jean': 13345,\n",
              " 'pierre': 18160,\n",
              " 'jeunet': 13393,\n",
              " 'responsible': 20251,\n",
              " 'directing': 7610,\n",
              " '2001': 429,\n",
              " 'starred': 22835,\n",
              " 'role': 20656,\n",
              " 'critically': 6589,\n",
              " 'acclaimed': 1452,\n",
              " 'dirty': 7625,\n",
              " 'pretty': 18763,\n",
              " 'oscar': 17263,\n",
              " 'preferring': 18674,\n",
              " 'name': 16391,\n",
              " 'hollywood': 11965,\n",
              " 'kate': 13661,\n",
              " 'beckinsale': 3320,\n",
              " 'widely': 26191,\n",
              " 'tipped': 24282,\n",
              " 'possibility': 18538,\n",
              " 'alongside': 2012,\n",
              " 'vanessa': 25453,\n",
              " 'paradis': 17622,\n",
              " 'juliette': 13556,\n",
              " 'binoche': 3611,\n",
              " 'thriller': 24165,\n",
              " 'upon': 25313,\n",
              " '17': 249,\n",
              " 'centred': 4953,\n",
              " 'global': 10846,\n",
              " 'conspiracy': 6083,\n",
              " 'surrounding': 23464,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZPY0N9xZh75"
      },
      "source": [
        "16. Run the SVD function with different values for components: 1, 2, 4, 5, 10, 15, 20, 50, 100. Plot the explained variance ratio for each component of Truncated SVD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "i9QzELaWZwbA",
        "outputId": "f8c24614-155c-4a95-be98-353b06a7508e"
      },
      "source": [
        "n_comp = [1, 2, 4, 5, 10, 15, 20, 50, 100] # list containing different values of components\n",
        "explained = [] # explained variance ratio for each component of Truncated SVD\n",
        "for x in n_comp:\n",
        "    svd = TruncatedSVD(n_components=x, random_state=SEED)\n",
        "    svd.fit(Xc)\n",
        "    explained.append(svd.explained_variance_ratio_.sum())\n",
        "    print(\"Number of components = %r and explained variance = %r\"%(x,svd.explained_variance_ratio_.sum()))\n",
        "\n",
        "plt.plot(n_comp, explained)\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel(\"Explained Variance\")\n",
        "plt.title(\"Plot of Number of components v/s explained variance\")\n",
        "plt.show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of components = 1 and explained variance = 0.8302335701200946\n",
            "Number of components = 2 and explained variance = 0.9165093632208307\n",
            "Number of components = 4 and explained variance = 0.9291569440678307\n",
            "Number of components = 5 and explained variance = 0.9344860554115808\n",
            "Number of components = 10 and explained variance = 0.9477460316797052\n",
            "Number of components = 15 and explained variance = 0.952973012013585\n",
            "Number of components = 20 and explained variance = 0.9560370191126837\n",
            "Number of components = 50 and explained variance = 0.9645716958622753\n",
            "Number of components = 100 and explained variance = 0.9711054139797318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gALVOFza1yk"
      },
      "source": [
        "17. How many components are needed to explain at least 95% of the variance?\n",
        "\n",
        "Based on the selected values, it seems 15 components are needed to explain 95% of the variance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tppdZlPTa0DD"
      },
      "source": [
        "clf6 = Pipeline([\n",
        "    ('vectorizer', CountVectorizer()),\n",
        "    ('feature_extraction', TfidfTransformer()),\n",
        "    ('feature_selection', TruncatedSVD(n_components=15, random_state=SEED)),\n",
        "    ('classification', LinearSVC())\n",
        "])"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxVUwoM8bM42",
        "outputId": "65250c56-fbea-4dc3-afa1-8a37199cba04"
      },
      "source": [
        "clf6.fit(X_train, y_train)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabula...\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('feature_selection',\n",
              "                 TruncatedSVD(algorithm='randomized', n_components=15, n_iter=5,\n",
              "                              random_state=321, tol=0.0)),\n",
              "                ('classification',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o55lhpXJbS34",
        "outputId": "1a7d46ed-888c-4737-eff1-5c419499a57b"
      },
      "source": [
        "y_pred6 = clf6.predict(X_test)\n",
        "print(metrics.classification_report(y_test, y_pred6, target_names=data.target_names))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.91      0.92      0.92        92\n",
            "entertainment       1.00      0.94      0.97        84\n",
            "     politics       0.91      0.92      0.92        77\n",
            "        sport       0.99      1.00      1.00       111\n",
            "         tech       0.94      0.96      0.95        81\n",
            "\n",
            "     accuracy                           0.95       445\n",
            "    macro avg       0.95      0.95      0.95       445\n",
            " weighted avg       0.95      0.95      0.95       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8-x1UJdbZoZ"
      },
      "source": [
        "19. Can you make a plot of accuracies of your 5 pipelines?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBmlWg_hpHjJ",
        "outputId": "95497e73-ea43-4a5c-c72c-5c440afa5375"
      },
      "source": [
        "SEED = 321\n",
        "\n",
        "pl = Pipeline([\n",
        "    ('vectorizer', CountVectorizer()),\n",
        "    ('feature_extraction', TfidfTransformer()),\n",
        "    ('feature_selection', \"passthrough\"),\n",
        "    ('classification', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "# train the pipeline/model\n",
        "pl.fit(X_train, y_train)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabula...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=None, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHhrTBC7tSY-",
        "outputId": "395d30bb-7cae-4f6f-d331-d3d7f901d0df"
      },
      "source": [
        "%%time\n",
        "# create parameter grid to search on \n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# tuning different hyper parameters on different models\n",
        "param_grid = [\n",
        "    {   \"feature_selection\": [\"passthrough\"],\n",
        "        \"classification\": [RandomForestClassifier()],\n",
        "    },\n",
        "    {   \"feature_selection\": [SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))],\n",
        "        \"classification\": [RandomForestClassifier()],\n",
        "    },\n",
        "    {   \"feature_selection\": [SelectKBest(chi2, k=20)],\n",
        "        \"classification\": [RandomForestClassifier()],\n",
        "    },\n",
        "    {   \"feature_selection\": [SelectKBest(chi2, k=200)],\n",
        "        \"classification\": [RandomForestClassifier()],\n",
        "    },\n",
        "    {   \"feature_selection\": [SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))],\n",
        "        \"classification\": [MultinomialNB(alpha=0.01)],\n",
        "    },\n",
        "    {   \"feature_selection\": [TruncatedSVD(n_components=15, random_state=SEED)],\n",
        "        \"classification\": [LinearSVC()],\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "# # construct gridsearch\n",
        "\n",
        "# # standard\n",
        "GS = GridSearchCV(pl, param_grid=param_grid, scoring=\"f1_weighted\")\n",
        "\n",
        "# # multiple\n",
        "# GS = GridSearchCV(pl, param_grid=param_grid, scoring=[\"balanced_accuracy\", \"f1\"], refit=False)\n",
        "\n",
        "# train gridsearch\n",
        "GS.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "resultsDF = pd.DataFrame(GS.cv_results_)\\\n",
        "    .filter(regex=r\"^(?!.*(split|time)).*$\")\\\n",
        "    .set_index(\"rank_test_score\").sort_index()\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 45.8 s, sys: 5.64 s, total: 51.5 s\n",
            "Wall time: 48.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "d1vQfNnX9_FC",
        "outputId": "baeba6cb-09cd-48b2-b3b6-948e52912056"
      },
      "source": [
        "# show results\n",
        "resultsDF"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>param_classification</th>\n",
              "      <th>param_feature_selection</th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rank_test_score</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MultinomialNB(alpha=0.01, class_prior=None, fi...</td>\n",
              "      <td>SelectFromModel(estimator=LinearSVC(C=1.0, cla...</td>\n",
              "      <td>{'classification': MultinomialNB(alpha=0.01, c...</td>\n",
              "      <td>0.967966</td>\n",
              "      <td>0.014729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n",
              "      <td>SelectFromModel(estimator=LinearSVC(C=1.0, cla...</td>\n",
              "      <td>{'classification': RandomForestClassifier(boot...</td>\n",
              "      <td>0.954967</td>\n",
              "      <td>0.014795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LinearSVC(C=1.0, class_weight=None, dual=True,...</td>\n",
              "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
              "      <td>{'classification': LinearSVC(C=1.0, class_weig...</td>\n",
              "      <td>0.953878</td>\n",
              "      <td>0.014791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n",
              "      <td>passthrough</td>\n",
              "      <td>{'classification': RandomForestClassifier(boot...</td>\n",
              "      <td>0.953180</td>\n",
              "      <td>0.019248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n",
              "      <td>SelectKBest(k=200, score_func=&lt;function chi2 a...</td>\n",
              "      <td>{'classification': RandomForestClassifier(boot...</td>\n",
              "      <td>0.947297</td>\n",
              "      <td>0.011941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n",
              "      <td>SelectKBest(k=20, score_func=&lt;function chi2 at...</td>\n",
              "      <td>{'classification': RandomForestClassifier(boot...</td>\n",
              "      <td>0.718039</td>\n",
              "      <td>0.026869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              param_classification  ... std_test_score\n",
              "rank_test_score                                                     ...               \n",
              "1                MultinomialNB(alpha=0.01, class_prior=None, fi...  ...       0.014729\n",
              "2                RandomForestClassifier(bootstrap=True, ccp_alp...  ...       0.014795\n",
              "3                LinearSVC(C=1.0, class_weight=None, dual=True,...  ...       0.014791\n",
              "4                RandomForestClassifier(bootstrap=True, ccp_alp...  ...       0.019248\n",
              "5                RandomForestClassifier(bootstrap=True, ccp_alp...  ...       0.011941\n",
              "6                RandomForestClassifier(bootstrap=True, ccp_alp...  ...       0.026869\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    }
  ]
}